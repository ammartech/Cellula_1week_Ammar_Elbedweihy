{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM Text Classification Training\n",
        "\n",
        "This notebook trains a simple LSTM model for text classification.\n",
        "\n",
        "ðŸ“Œ **Expectations:**\n",
        "- Uses F1 as the **primary** evaluation metric\n",
        "- Saves accuracy/F1 curves and a **confusion matrix**\n",
        "- Produces a small PDF results report\n",
        "\n",
        "ðŸ”§ **Dataset format**: CSV with columns `text` and `label`. Set `DATASET_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# If running on Colab, uncomment the next line\n",
        "# !pip install torch torchvision torchaudio torchtext==0.18.0 scikit-learn pandas matplotlib reportlab tqdm --quiet\n",
        "\n",
        "import os, math, random, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "from datetime import datetime\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "# ---- Paths ----\n",
        "DATASET_PATH = \"/content/dataset.csv\"  # <-- change this\n",
        "OUT_DIR = \"outputs_lstm\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Hyperparams ----\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 64\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 128\n",
        "NUM_EPOCHS = 5\n",
        "LR = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ---------------- Data ----------------\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "assert \"text\" in df.columns and \"label\" in df.columns, \"CSV must have columns: text, label\"\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df[\"y\"] = le.fit_transform(df[\"label\"].astype(str))\n",
        "\n",
        "# Simple tokenizer (whitespace + frequency vocab)\n",
        "# For production, prefer a real tokenizer, but this keeps it dependency-light for an LSTM example.\n",
        "def tokenize(s):\n",
        "    return str(s).lower().split()\n",
        "\n",
        "# Build vocab\n",
        "from collections import Counter\n",
        "all_tokens = [tok for s in df[\"text\"].astype(str).tolist() for tok in tokenize(s)]\n",
        "freq = Counter(all_tokens)\n",
        "# keep top N words\n",
        "MAX_VOCAB = 20000\n",
        "vocab_words = [w for w,_ in freq.most_common(MAX_VOCAB-2)]\n",
        "stoi = {\"<pad>\":0, \"<unk>\":1}\n",
        "for i,w in enumerate(vocab_words, start=2):\n",
        "    stoi[w] = i\n",
        "itos = {i:w for w,i in stoi.items()}\n",
        "\n",
        "def encode(s, max_len=MAX_LEN):\n",
        "    toks = tokenize(s)\n",
        "    ids = [stoi.get(t,1) for t in toks][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids = ids + [0]*(max_len-len(ids))\n",
        "    return ids\n",
        "\n",
        "X = np.stack([encode(s) for s in df[\"text\"].astype(str)])\n",
        "y = df[\"y\"].values\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "X_train, X_val,  y_train, y_val  = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train)\n",
        "\n",
        "class TxtDS(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "tr_loader = DataLoader(TxtDS(X_train,y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "va_loader = DataLoader(TxtDS(X_val,y_val), batch_size=BATCH_SIZE)\n",
        "te_loader = DataLoader(TxtDS(X_test,y_test), batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ---------------- Model ----------------\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)                # [B, T, E]\n",
        "        out,_ = self.lstm(x)           # [B, T, 2H]\n",
        "        out = out[:, -1, :]            # last timestep\n",
        "        out = self.drop(out)\n",
        "        return self.fc(out)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier(vocab_size=len(stoi), embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM, num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ---------------- Train & Eval ----------------\n",
        "def run_epoch(loader, train=True):\n",
        "    if train: model.train()\n",
        "    else: model.eval()\n",
        "    losses, preds, gts = [], [], []\n",
        "    with torch.set_grad_enabled(train):\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            if train: optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "            preds.extend(torch.argmax(logits, dim=-1).detach().cpu().tolist())\n",
        "            gts.extend(yb.detach().cpu().tolist())\n",
        "    return np.mean(losses), accuracy_score(gts, preds), f1_score(gts, preds, average=\"weighted\"), np.array(preds), np.array(gts)\n",
        "\n",
        "history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[], \"train_f1\":[], \"val_f1\":[]}\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    tr_loss, tr_acc, tr_f1, _, _ = run_epoch(tr_loader, train=True)\n",
        "    va_loss, va_acc, va_f1, _, _ = run_epoch(va_loader, train=False)\n",
        "    history[\"train_loss\"].append(tr_loss); history[\"val_loss\"].append(va_loss)\n",
        "    history[\"train_acc\"].append(tr_acc);   history[\"val_acc\"].append(va_acc)\n",
        "    history[\"train_f1\"].append(tr_f1);     history[\"val_f1\"].append(va_f1)\n",
        "    print(f\"Epoch {epoch:02d} | loss {va_loss:.4f} | acc {va_acc:.4f} | F1 {va_f1:.4f}\")\n",
        "\n",
        "te_loss, te_acc, te_f1, te_pred, te_true = run_epoch(te_loader, train=False)\n",
        "print(\"\\nTEST -> loss {:.4f} | acc {:.4f} | F1 {:.4f}\".format(te_loss, te_acc, te_f1))\n",
        "\n",
        "# --- Plots ---\n",
        "plt.figure()\n",
        "plt.plot(history[\"train_acc\"], label=\"train_acc\")\n",
        "plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy\"); plt.xlabel(\"epoch\"); plt.ylabel(\"acc\"); plt.legend(); plt.tight_layout()\n",
        "acc_png = os.path.join(OUT_DIR, \"accuracy.png\"); plt.savefig(acc_png, dpi=150)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history[\"train_f1\"], label=\"train_f1\")\n",
        "plt.plot(history[\"val_f1\"], label=\"val_f1\")\n",
        "plt.title(\"F1 score\"); plt.xlabel(\"epoch\"); plt.ylabel(\"F1\"); plt.legend(); plt.tight_layout()\n",
        "f1_png = os.path.join(OUT_DIR, \"f1.png\"); plt.savefig(f1_png, dpi=150)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(te_true, te_pred, labels=list(range(num_classes)))\n",
        "plt.figure()\n",
        "import itertools\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix'); plt.colorbar()\n",
        "tick_marks = np.arange(num_classes)\n",
        "plt.xticks(tick_marks, tick_marks); plt.yticks(tick_marks, tick_marks)\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\")\n",
        "plt.tight_layout(); plt.ylabel('True'); plt.xlabel('Pred')\n",
        "cm_png = os.path.join(OUT_DIR, \"confusion_matrix.png\"); plt.savefig(cm_png, dpi=150)\n",
        "\n",
        "# --- PDF report ---\n",
        "pdf_path = os.path.join(OUT_DIR, \"LSTM_results.pdf\")\n",
        "c = canvas.Canvas(pdf_path, pagesize=A4)\n",
        "W, H = A4\n",
        "y = H - 50\n",
        "c.setFont(\"Helvetica-Bold\", 14)\n",
        "c.drawString(40, y, \"LSTM Training Results\")\n",
        "y -= 20\n",
        "c.setFont(\"Helvetica\", 10)\n",
        "c.drawString(40, y, f\"Generated: {datetime.now()}\")\n",
        "y -= 20\n",
        "c.drawString(40, y, f\"Test Acc: {te_acc:.4f} | Test F1 (weighted): {te_f1:.4f} | Test Loss: {te_loss:.4f}\")\n",
        "y -= 20\n",
        "# Add plots\n",
        "for img in [acc_png, f1_png, cm_png]:\n",
        "    if y < 200:\n",
        "        c.showPage(); y = H - 50\n",
        "    c.drawImage(img, 40, y-160, width=300, height=160)\n",
        "    y -= 180\n",
        "c.showPage(); c.save()\n",
        "\n",
        "print(f\"Saved PDF -> {pdf_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference and Batch Evaluation\n",
        "\n",
        "Use a fine-tuned checkpoint directory to run predictions and compute F1/Accuracy on a test CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -U transformers datasets scikit-learn pandas matplotlib --quiet\n",
        "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "CHECKPOINT_DIR = \"/content/outputs_distilbert_lora\"   # change to your best checkpoint\n",
        "TEST_CSV = \"/content/test.csv\"                        # CSV with text,label\n",
        "\n",
        "df = pd.read_csv(TEST_CSV)\n",
        "labels = sorted(df[\"label\"].astype(str).unique().tolist())\n",
        "label2id = {l:i for i,l in enumerate(labels)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "df[\"label_id\"] = df[\"label\"].astype(str).map(label2id)\n",
        "\n",
        "ds = Dataset.from_pandas(df[[\"text\",\"label_id\"]])\n",
        "tok = AutoTokenizer.from_pretrained(CHECKPOINT_DIR)\n",
        "def preprocess(ex): \n",
        "    out = tok(ex[\"text\"], truncation=True, max_length=256)\n",
        "    out[\"labels\"] = ex[\"label_id\"]\n",
        "    return out\n",
        "ds = ds.map(preprocess, batched=True, remove_columns=ds.column_names)\n",
        "collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT_DIR, num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
        "\n",
        "args = TrainingArguments(\"/content/_tmp_eval\", per_device_eval_batch_size=32)\n",
        "trainer = Trainer(model=model, args=args, data_collator=collator, tokenizer=tok)\n",
        "preds = np.argmax(trainer.predict(ds).predictions, axis=-1)\n",
        "f1 = f1_score(ds[\"labels\"], preds, average=\"weighted\")\n",
        "acc = accuracy_score(ds[\"labels\"], preds)\n",
        "print(\"F1:\", f1, \"Acc:\", acc)\n",
        "\n",
        "cm = confusion_matrix(ds[\"labels\"], preds, labels=list(range(len(labels))))\n",
        "plt.figure(); plt.imshow(cm, interpolation='nearest'); plt.title('Confusion Matrix'); plt.colorbar()\n",
        "plt.tight_layout(); plt.ylabel('True'); plt.xlabel('Pred')\n",
        "os.makedirs(\"outputs_eval\", exist_ok=True)\n",
        "plt.savefig(\"outputs_eval/confusion_matrix.png\", dpi=150)\n",
        "with open(\"outputs_eval/metrics.txt\",\"w\") as f:\n",
        "    f.write(f\"F1={f1}\\nACC={acc}\\n\")\n",
        "print(\"Saved to outputs_eval\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}